{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9252/3306409785.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "\n",
    "from scipy.io import wavfile\n",
    "from glob import glob\n",
    "\n",
    "from kapre.composed import get_melspectrogram_layer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint\n",
    "from tensorflow.keras.layers import TimeDistributed, LayerNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_root = 'raw_data'\n",
    "dst_root = 'clean'\n",
    "dt = 1.0\n",
    "sample_f = 44100\n",
    "dummy_file = 'finger_snaps_1_4'\n",
    "threshold = 120\n",
    "\n",
    "batch_size = 16\n",
    "model_type = \"conv2d\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Conv2D(n_classes=2, sf = sample_f, dt = dt):\n",
    "    input_shape = (int(sf*dt),1)\n",
    "    i = get_melspectrogram_layer(input_shape = input_shape, \n",
    "                                 n_mels = 40,\n",
    "                                 pad_end = True,\n",
    "                                 n_fft=512,\n",
    "                                 win_length = 400,\n",
    "                                 hop_length = 160,\n",
    "                                 sample_rate = sf,\n",
    "                                 return_decibel = True,\n",
    "                                 input_data_format=\"channels_last\",\n",
    "                                 output_data_format=\"channels_last\")\n",
    "    # output format : batch, time, frequency, channels\n",
    "\n",
    "    x = LayerNormalization(axis=2, name='batch_norm')(i.output)\n",
    "    x = layers.Conv2D(8, kernel_size=(7,7), activation='tanh', padding='same', name='conv2d_tanh')(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2,2), padding='same', name='max_pool_2d_1')(x)\n",
    "    x = layers.Conv2D(16, kernel_size=(5,5), activation='relu', padding='same', name='conv2d_relu_1')(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2,2), padding='same', name='max_pool_2d_2')(x)\n",
    "    x = layers.Conv2D(16, kernel_size=(3,3), activation='relu', padding='same', name='conv2d_relu_2')(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2,2), padding='same', name='max_pool_2d_3')(x)\n",
    "    x = layers.Conv2D(32, kernel_size=(3,3), activation='relu', padding='same', name='conv2d_relu_3')(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2,2), padding='same', name='max_pool_2d_4')(x)\n",
    "    x = layers.Conv2D(32, kernel_size=(3,3), activation='relu', padding='same', name='conv2d_relu_4')(x)\n",
    "    x = layers.Flatten(name='flatten')(x)\n",
    "    x = layers.Dropout(rate=0.1, name='dropout_2')(x)\n",
    "    x = layers.Dense(64, activation='relu', activity_regularizer=l2(0.001), name='dense_1')(x)\n",
    "    o = layers.Dense(n_classes, activation='softmax', name='softmax')(x)\n",
    "    model = Model(inputs=i.input, outputs=o, name='2d_convolution')\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy']) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self,wav_paths,labels,sf,\n",
    "                    dt, n_classes,batch_size = 32, shuffle = True):\n",
    "        self.wav_paths = wav_paths\n",
    "        self.labels = labels\n",
    "        self.sf = sf\n",
    "        self.dt = dt\n",
    "        self.n_classes = n_classes\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.wav_paths)/self.batch_size))\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        \n",
    "        wav_paths = [self.wav_paths[k] for k in indexes]\n",
    "        labels = [self.labels[k] for k in indexes]\n",
    "\n",
    "        X = np.empty((self.batch_size,int(self.sf*self.dt),1),dtype=np.float32)\n",
    "        Y = np.empty((self.batch_size, self.n_classes), dtype=np.float32)\n",
    "\n",
    "        for i, (path, label) in enumerate(zip(wav_paths,labels)):\n",
    "            rate, wav = wavfile.read(path)\n",
    "            X[i,] = wav.reshape(-1,1)\n",
    "            Y[i,] = to_categorical(label,num_classes=self.n_classes)\n",
    "        return X, Y\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.wav_paths))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(src = dst_root, sf=sample_f, dt=dt, bs = batch_size, model_type = model_type):\n",
    "\n",
    "    csv_path = os.path.join(\"logs\",f\"{model_type}_history.csv\")\n",
    "\n",
    "    n_classes = len(os.listdir(src))\n",
    "\n",
    "    wav_paths = glob('{}/**'.format(src), recursive=True)\n",
    "    wav_paths = [x.replace(os.sep, '/') for x in wav_paths if '.wav' in x]\n",
    "    classes = sorted(os.listdir(src))\n",
    "    le = LabelEncoder()\n",
    "    le.fit(classes)\n",
    "    labels = [os.path.split(x)[0].split('/')[-1] for x in wav_paths]\n",
    "    labels = le.transform(labels)\n",
    "    \n",
    "    wav_train, wav_val, label_train, label_val = train_test_split(wav_paths,labels,test_size = 0.25, random_state=37)\n",
    "\n",
    "    assert len(label_train) >= bs, \"Number of train samples must be >= than batch_size\"\n",
    "    if len(set(label_train))!= n_classes:\n",
    "        warnings.warn(f\"Found {len(set(label_train))}/{n_classes} classes in training data. Increase data size or change random_state.\")\n",
    "    if len(set(label_val)) != n_classes:\n",
    "        warnings.warn(f\"Found {len(set(label_val))}/{n_classes} classes in validation data. Increase data size or change random_state.\")\n",
    "\n",
    "    tg = DataGenerator(wav_train,label_train,sf,dt,n_classes,batch_size)\n",
    "    vg = DataGenerator(wav_val,label_val,sf,dt,n_classes,batch_size)\n",
    "\n",
    "    model = Conv2D(n_classes,sf,dt)\n",
    "    cp = ModelCheckpoint(f\"models/{model_type}.h5\",monitor = \"val_loss\", \n",
    "                         save_best_only = True, save_weights_only = False,\n",
    "                         mode=\"auto\", save_freq = \"epoch\",verbose = 0)\n",
    "    csv_logger = CSVLogger(csv_path,append=False)\n",
    "    model.fit(tg,validation_data = vg, epochs = 15, verbose = 1,\n",
    "                callbacks=[csv_logger,cp])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "15/15 [==============================] - 16s 799ms/step - loss: 0.6059 - accuracy: 0.6625 - val_loss: 0.4677 - val_accuracy: 0.7875\n",
      "Epoch 2/15\n",
      "15/15 [==============================] - 10s 699ms/step - loss: 0.4368 - accuracy: 0.8208 - val_loss: 0.4121 - val_accuracy: 0.8125\n",
      "Epoch 3/15\n",
      "15/15 [==============================] - 10s 640ms/step - loss: 0.3326 - accuracy: 0.8708 - val_loss: 0.5572 - val_accuracy: 0.8250\n",
      "Epoch 4/15\n",
      "15/15 [==============================] - 10s 656ms/step - loss: 0.2460 - accuracy: 0.9083 - val_loss: 0.3363 - val_accuracy: 0.8375\n",
      "Epoch 5/15\n",
      "15/15 [==============================] - 10s 686ms/step - loss: 0.1618 - accuracy: 0.9583 - val_loss: 0.3974 - val_accuracy: 0.8875\n",
      "Epoch 6/15\n",
      "15/15 [==============================] - 10s 708ms/step - loss: 0.1722 - accuracy: 0.9417 - val_loss: 0.2702 - val_accuracy: 0.8625\n",
      "Epoch 7/15\n",
      "15/15 [==============================] - 10s 641ms/step - loss: 0.1230 - accuracy: 0.9667 - val_loss: 0.2958 - val_accuracy: 0.8750\n",
      "Epoch 8/15\n",
      "15/15 [==============================] - 10s 659ms/step - loss: 0.0842 - accuracy: 0.9792 - val_loss: 0.3356 - val_accuracy: 0.8625\n",
      "Epoch 9/15\n",
      "15/15 [==============================] - 9s 625ms/step - loss: 0.0651 - accuracy: 0.9917 - val_loss: 0.3280 - val_accuracy: 0.8750\n",
      "Epoch 10/15\n",
      "15/15 [==============================] - 10s 685ms/step - loss: 0.0530 - accuracy: 0.9917 - val_loss: 0.3241 - val_accuracy: 0.8875\n",
      "Epoch 11/15\n",
      "15/15 [==============================] - 10s 648ms/step - loss: 0.0433 - accuracy: 0.9958 - val_loss: 0.3477 - val_accuracy: 0.8750\n",
      "Epoch 12/15\n",
      "15/15 [==============================] - 10s 645ms/step - loss: 0.0399 - accuracy: 0.9958 - val_loss: 0.3231 - val_accuracy: 0.8750\n",
      "Epoch 13/15\n",
      "15/15 [==============================] - 9s 621ms/step - loss: 0.0373 - accuracy: 0.9958 - val_loss: 0.3341 - val_accuracy: 0.8750\n",
      "Epoch 14/15\n",
      "15/15 [==============================] - 10s 664ms/step - loss: 0.0360 - accuracy: 0.9958 - val_loss: 0.2569 - val_accuracy: 0.9000\n",
      "Epoch 15/15\n",
      "15/15 [==============================] - 10s 644ms/step - loss: 0.0357 - accuracy: 0.9958 - val_loss: 0.3490 - val_accuracy: 0.8750\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ee0a0476f8bb4eaad7b141329153ce7d3ac52888864493190375b1b47c8c17da"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
